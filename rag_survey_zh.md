# 大语言模型的检索增强生成技术（RAG）综述

Yunfan Gao 1 , Yun Xiong 2 , Xinyu Gao 2 , Kangxiang Jia 2 , Jinliu Pan 2 , Yuxi Bi 3 , Yi Dai1 , **Jiawei Sun**1 and **Haofen Wang** 1,3 ∗
1 Shanghai Research Institute for Intelligent Autonomous Systems, Tongji University
2 Shanghai Key Laboratory of Data Science, School of Computer Science, Fudan University
3 College of Design and Innovation,Tongji University gaoyunfan1602@gmail.com

## 摘要

大型语言模型（LLMs）虽然能力强大，但在实际应用中还存在一些问题，比如产生不准确的信息、知识更新慢，以及答案的不透明性。检索增强生成（Retrieval-Augmented Generation, RAG）是指在大型语言模型回答问题前，先从外部知识库中检索相关信息的过程。

RAG 被证实可以显著提升答案的准确度，尤其在知识密集型任务中，能有效减少模型生成的错误信息。用户可以通过查看引用的信息来源来核实答案的正确性，这样也增强了对模型输出结果的信任。

此外，RAG 还有助于快速更新知识和引入特定领域的专业知识。

RAG 将大语言模型（LLMs）中的参数化知识与非参数化的外部知识库有效结合，成为了实现大型语言模型的关键方法之一。本文梳理了大语言模型时代 RAG 的发展模式，概括了三种模式：初级 RAG（Naive RAG）、高级 RAG（Advanced RAG）和模块化 RAG（Modular RAG）。接着，文章总结了 RAG 的三大核心组成部分：检索器（retriever）、生成器（generator）和增强方法（augmentation methods），并详细介绍了每个部分的关键技术。此外，文中还探讨了如何评价 RAG 模型的效果，介绍了两种评估 RAG 的方法，并强调了评估过程中的关键指标和能力，同时展示了最新的自动评估框架。最后，文章从纵向优化、横向扩展能力以及 RAG 的技术架构和生态系统三个角度，提出了未来研究的潜在方向。

## 1. 介绍

大语言模型（LLMs）的能力在自然语言处理（NLP）领域达到了前所未有的高度。

包括 OpenAI 在 2020 年和 2023 年发布的 GPT 系列模型 [Brown *et al.*, 2020; OpenAI, 2023]、Touvron *et al.* 在 2023 年提出的 LLama 系列模型，以及 Google 在同年推出的 Gemini 等大型语言模型，在多项评估标准上展现了卓越的语言理解和知识运用能力，甚至在多个领域超过了人类的表现 [Wang *et al.*, 2019; Hendrycks *et al.*, 2020; Srivastava *et al.*, 2022]。

尽管如此，大语言模型仍存在不少需要改进的地方。

大语言模型在某些情况下会产生不准确的信息 [Zhang *et al.*, 2023b]，特别是在面对特定领域或复杂问题时，它们的知识储备可能显得不足 [Kandpal *et al.*, 2023]。举个例子，当用户查询的信息超出了模型的训练数据范围，或者需要获取最新的数据时，大语言模型可能就难以给出正确的答案。这种局限性在将生成式人工智能应用到真实世界的生产环境中尤其成问题，因为仅仅依赖一个不透明的大语言模型往往是不够的。

传统的神经网络通过微调来适应特定的领域或私有信息，这一过程涉及到对知识的参数化处理。虽然这种方法能够带来显著的效果，但它同时也需要耗费大量的计算资源，付出高昂的成本，并且依赖于专业的技术知识，因此在面对不断更新的信息环境时，它的适应性并不理想。参数化知识与非参数化知识各有其用武之地。参数化知识通过训练大语言模型得到，并储存在神经网络的权重里，它代表了模型对训练数据的理解和泛化能力，是生成回答的基础。而非参数化知识则存储在外部的知识库中，比如向量数据库，它不是直接嵌入模型中，而是作为一种可以更新的附加信息。非参数化知识使得大语言模型能够访问并利用最新的或特定领域的信息，从而提升了回答的准确性和相关性。

大语言模型（LLMs）通常将从大量文本资料中学到的知识，以参数的形式储存在模型之中。但是，这种完全基于参数的模型存在一些限制。首先，模型难以完全记住训练资料中的所有知识，尤其是那些不常见或特别具体的信息。

其次，因为模型的参数无法实时更新，所以随着时间的推移，这些基于参数的知识可能会逐渐过时。最后，随着模型参数数量的增加，无论是在训练还是在使用时，所需的计算资源也会随之增加。为了克服这些限制，语言模型可以采用半参数化的策略，即将一个非参数化的语料库数据库与参数化模型结合起来。这种结合的方法称为检索增强生成（Retrieval-Augmented Generation，RAG）。

检索增强生成（Retrieval-Augmented Generation，RAG）这一概念最早由 [Lewis *et al.*, 2020] 在他们的研究中提出。RAG 的设计是将一个预先训练好的信息检索系统与一个预先训练好的序列到序列（seq2seq）生成模型结合起来，并通过端到端的精细调校，使得模型以一种更易于理解和模块化的方式来处理和整合知识。在大型模型成为主流之前，RAG 主要致力于优化整个模型的直接性能。在检索环节，广泛采用了如密集通道检索（Dense Passage Retrieval，DPR）[Karpukhin *et al.*, 2020] 这样的基于向量的密集检索技术，而在生成环节则常常训练规模较小的模型。

由于参数总体较小，检索器和生成器通常需要同步进行端到端训练或者精细调优 [Izacard et al., 2022]。

随着 ChatGPT 这类大语言模型（LLM）的涌现，生成型语言模型在各类语言任务中展现出了卓越的表现，成为了主流 [Bai et al., 2022, OpenAI, 2023, Touvron et al., 2023, Google, 2023]。

但是，大语言模型还是遇到了一些挑战，比如产生错误信息（通常称为“幻觉”）[Yao et al., 2023, Bang et al., 2023]、知识更新以及数据问题。

这些问题影响了大语言模型在处理一些关键任务时的可靠性，尤其是在那些需要广泛知识的知识密集型任务上，比如开放域问答 [Chen and Yih, 2020, Reddy et al., 2019, Kwiatkowski et al., 2019] 和常识推理 [Clark et al., ### 直译
由于整体参数规模较小，检索器和生成器通常会进行同步的端到端训练或微调 [Izacard et al., 2022]。

在像 ChatGPT 这样的大语言模型（LLM）出现之后，生成型语言模型在各种语言任务上展现出了令人印象深刻的性能，从而变得占主导地位 [Bai et al., 2022, OpenAI, 2023, Touvron et al., 2023, Google, 2023]。

然而，大语言模型仍然面临着如幻觉 [Yao et al., 2023, Bang et al., 2023]、知识更新和数据相关问题等挑战。

这影响了大语言模型（LLM）的可靠性，它们在某些关键任务场景中表现不佳，特别是在那些需要获取大量知识的知识密集型任务上，如开放领域的问题解答（Chen 和 Yih, 2020; Reddy 等人, 2019; Kwiatkowski 等人, 2019）和常识性推理（Clark 等人, 2019; Bisk 等人, 2020）。

模型参数所蕴含的知识可能是不完整和有限的。

随后的研究发现，将 RAG 结合到大型模型的情境内学习（In-Context Learning, ICL）过程中，能够有效缓解前述的问题，并且这种改进既显著又容易实施。在模型进行推理时，RAG 能够动态地从外部知识库中提取信息，并利用这些信息来构建答案，这样不仅大幅提升了回答的精确度和相关性，还有效避免了大语言模型中出现的错误信息生成问题。这种技术在大语言模型推出后迅速流行起来，成为了提升聊天机器人性能和增强大语言模型实用性的前沿技术。RAG 通过将确凿的知识与大语言模型训练时的参数分开，巧妙地把生成模型的强大生成能力和信息检索模块的灵活性结合起来，为解决模型内在的知识不完整性问题提供了一个高效的方案。

这篇论文全面梳理了检索增强生成（RAG）的研究方法和未来发展路径，把相关研究归纳为三种主流模式：初级 RAG、高级 RAG 和模块化 RAG。文章进一步详细阐述了 RAG 的三大核心要素：检索、增强和生成，强调了 RAG 的改进方向和技术特点。在探讨增强技术的部分，研究被划分为三个层面：RAG 的增强阶段、数据源和过程。同时，论文还综述了评估体系、适用场景及其他与 RAG 相关的内容。读者通过本文能够对大语言模型及检索增强生成有一个系统的理解，熟悉知识检索增强的发展轨迹和关键技术，从而辨别不同技术的优劣，确定适用的场景，并探讨目前实际应用中的典型案例。值得一提的是，在先前的研究中，Feng 等人系统性地回顾了结合大型模型与知识的方法、应用和未来趋势，主要集中在知识编辑和检索增强方法上。特别值得一提的是，在之前的研究中，Feng 等[2023b] 对结合大语言模型（Large Language Model）和知识的方法、应用及未来趋势进行了系统性的综述，重点是知识编辑和知识检索的增强方法。而 Zhu 等[2023] 则介绍了针对大语言模型的检索系统的最新提升技术，特别是检索系统本身。

![1703158581561](image/rag_survey_zh/1703158581561.png)


